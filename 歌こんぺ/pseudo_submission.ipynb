{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore', pd.core.common.SettingWithCopyWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "\n",
    "N_CLASSES = 11\n",
    "\n",
    "\n",
    "df_train = pd.read_csv( \"train.csv\")\n",
    "df_test = pd.read_csv( \"test.csv\")\n",
    "df_sample_sub = pd.read_csv( \"sample_submit.csv\", header=None)\n",
    "df_sample_sub.columns = [\"index\", \"genre\"]\n",
    "df_genre_labels = pd.read_csv( \"genre_labels.csv\")\n",
    "\n",
    "\n",
    "def merge_train_test(df_train, df_test):\n",
    "    if \"genre\" not in df_test.columns.tolist():\n",
    "        df_test[\"genre\"] = -100\n",
    "    res = pd.concat([df_train, df_test])\n",
    "    res.reset_index(inplace=True, drop=True)\n",
    "    return res\n",
    "\n",
    "def split_train_test(df):\n",
    "    df_train = df[df[\"genre\"] != -100]\n",
    "    df_test = df[df[\"genre\"] == -100]\n",
    "    df_train.reset_index(inplace=True, drop=True)\n",
    "    df_test.reset_index(inplace=True, drop=True)\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "# parameters\n",
    "\n",
    "# def lgb_metric(preds, data):  \n",
    "#     pred_labels = preds.reshape(N_CLASSES, -1).argmax(axis=0)\n",
    "#     score = f1_score(data.get_label(), pred_labels, average=\"macro\")\n",
    "#     return \"macro_f1\", score, True\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": N_CLASSES,\n",
    "    #\"metric\": \"None\",\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"num_leaves\": 3,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    #\"colsample_bytree\": 1.0,\n",
    "    #\"feature_fraction\": 1.0,\n",
    "    #\"bagging_freq\": 0,\n",
    "    #\"bagging_fraction\": 1.0,\n",
    "    \"verbosity\": 0,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "knn_n_neighbors = 6\n",
    "\n",
    "\n",
    "# parameters - knn feature weights\n",
    "\n",
    "knn_features = [\n",
    "   'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "   'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "   'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "   'region_S', 'region_T', 'region_unknown',\n",
    "   'standardscaled_popularity', 'standardscaled_duration_ms',\n",
    "   'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "   'standardscaled_danceability', 'standardscaled_loudness',\n",
    "   'standardscaled_energy', 'standardscaled_liveness',\n",
    "   'standardscaled_speechiness', 'standardscaled_instrumentalness',\n",
    "   'standardscaled_log_tempo', 'standardscaled_num_nans'\n",
    "]\n",
    "\n",
    "dict_feature_weights = {}\n",
    "\n",
    "for col in [\n",
    "    'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "    'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "    'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "    'region_S', 'region_T', 'region_unknown'\n",
    "]:\n",
    "    dict_feature_weights[col] = 100.0\n",
    "\n",
    "for col in [\n",
    "    'standardscaled_duration_ms',\n",
    "    'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "    'standardscaled_danceability', 'standardscaled_loudness',\n",
    "    'standardscaled_energy', 'standardscaled_liveness',\n",
    "    'standardscaled_speechiness', 'standardscaled_instrumentalness'\n",
    "]:\n",
    "    dict_feature_weights[col] = 1.0\n",
    "\n",
    "dict_feature_weights[\"standardscaled_popularity\"] = 8.0\n",
    "dict_feature_weights[\"standardscaled_log_tempo\"] = 0.001\n",
    "dict_feature_weights[\"standardscaled_num_nans\"] = 100.0\n",
    "\n",
    "knn_feature_weights = np.array([dict_feature_weights[col] for col in knn_features])\n",
    "\n",
    "\n",
    "df_main = merge_train_test(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ fold 0 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.738405\tvalid_1's multi_logloss: 0.9264\n",
      "[600]\ttraining's multi_logloss: 0.65363\tvalid_1's multi_logloss: 0.911383\n",
      "[900]\ttraining's multi_logloss: 0.597472\tvalid_1's multi_logloss: 0.90952\n",
      "Early stopping, best iteration is:\n",
      "[819]\ttraining's multi_logloss: 0.611131\tvalid_1's multi_logloss: 0.908907\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.739219\tvalid_1's multi_logloss: 0.975418\n",
      "[600]\ttraining's multi_logloss: 0.655461\tvalid_1's multi_logloss: 0.96577\n",
      "[900]\ttraining's multi_logloss: 0.600852\tvalid_1's multi_logloss: 0.965676\n",
      "Early stopping, best iteration is:\n",
      "[761]\ttraining's multi_logloss: 0.623916\tvalid_1's multi_logloss: 0.964039\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.753605\tvalid_1's multi_logloss: 0.782907\n",
      "[600]\ttraining's multi_logloss: 0.672423\tvalid_1's multi_logloss: 0.744768\n",
      "[900]\ttraining's multi_logloss: 0.619459\tvalid_1's multi_logloss: 0.732021\n",
      "[1200]\ttraining's multi_logloss: 0.577274\tvalid_1's multi_logloss: 0.728983\n",
      "[1500]\ttraining's multi_logloss: 0.540854\tvalid_1's multi_logloss: 0.722764\n",
      "[1800]\ttraining's multi_logloss: 0.507478\tvalid_1's multi_logloss: 0.717385\n",
      "[2100]\ttraining's multi_logloss: 0.477082\tvalid_1's multi_logloss: 0.711775\n",
      "[2400]\ttraining's multi_logloss: 0.449044\tvalid_1's multi_logloss: 0.709701\n",
      "[2700]\ttraining's multi_logloss: 0.423429\tvalid_1's multi_logloss: 0.708228\n",
      "[3000]\ttraining's multi_logloss: 0.399741\tvalid_1's multi_logloss: 0.709517\n",
      "Early stopping, best iteration is:\n",
      "[2723]\ttraining's multi_logloss: 0.421525\tvalid_1's multi_logloss: 0.70795\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.743757\tvalid_1's multi_logloss: 0.844469\n",
      "[600]\ttraining's multi_logloss: 0.663718\tvalid_1's multi_logloss: 0.811451\n",
      "[900]\ttraining's multi_logloss: 0.610036\tvalid_1's multi_logloss: 0.801797\n",
      "[1200]\ttraining's multi_logloss: 0.566683\tvalid_1's multi_logloss: 0.795514\n",
      "[1500]\ttraining's multi_logloss: 0.528891\tvalid_1's multi_logloss: 0.791481\n",
      "[1800]\ttraining's multi_logloss: 0.495484\tvalid_1's multi_logloss: 0.795369\n",
      "Early stopping, best iteration is:\n",
      "[1595]\ttraining's multi_logloss: 0.517807\tvalid_1's multi_logloss: 0.791169\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.748035\tvalid_1's multi_logloss: 0.75963\n",
      "[600]\ttraining's multi_logloss: 0.665207\tvalid_1's multi_logloss: 0.73643\n",
      "[900]\ttraining's multi_logloss: 0.609799\tvalid_1's multi_logloss: 0.737488\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's multi_logloss: 0.644512\tvalid_1's multi_logloss: 0.735556\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.738356\tvalid_1's multi_logloss: 0.837322\n",
      "[600]\ttraining's multi_logloss: 0.655639\tvalid_1's multi_logloss: 0.820493\n",
      "[900]\ttraining's multi_logloss: 0.599921\tvalid_1's multi_logloss: 0.81782\n",
      "[1200]\ttraining's multi_logloss: 0.555848\tvalid_1's multi_logloss: 0.811317\n",
      "[1500]\ttraining's multi_logloss: 0.517421\tvalid_1's multi_logloss: 0.808873\n",
      "[1800]\ttraining's multi_logloss: 0.483353\tvalid_1's multi_logloss: 0.808481\n",
      "[2100]\ttraining's multi_logloss: 0.452935\tvalid_1's multi_logloss: 0.810691\n",
      "Early stopping, best iteration is:\n",
      "[1863]\ttraining's multi_logloss: 0.476788\tvalid_1's multi_logloss: 0.808018\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.753826\tvalid_1's multi_logloss: 0.823461\n",
      "[600]\ttraining's multi_logloss: 0.672652\tvalid_1's multi_logloss: 0.797612\n",
      "[900]\ttraining's multi_logloss: 0.619648\tvalid_1's multi_logloss: 0.788953\n",
      "[1200]\ttraining's multi_logloss: 0.575182\tvalid_1's multi_logloss: 0.785508\n",
      "[1500]\ttraining's multi_logloss: 0.536939\tvalid_1's multi_logloss: 0.786157\n",
      "Early stopping, best iteration is:\n",
      "[1267]\ttraining's multi_logloss: 0.566242\tvalid_1's multi_logloss: 0.78502\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.74436\tvalid_1's multi_logloss: 0.804776\n",
      "[600]\ttraining's multi_logloss: 0.660685\tvalid_1's multi_logloss: 0.792255\n",
      "Early stopping, best iteration is:\n",
      "[576]\ttraining's multi_logloss: 0.665778\tvalid_1's multi_logloss: 0.792054\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.73877\tvalid_1's multi_logloss: 0.916596\n",
      "[600]\ttraining's multi_logloss: 0.656911\tvalid_1's multi_logloss: 0.909724\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttraining's multi_logloss: 0.69466\tvalid_1's multi_logloss: 0.905273\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.747195\tvalid_1's multi_logloss: 0.821417\n",
      "[600]\ttraining's multi_logloss: 0.663054\tvalid_1's multi_logloss: 0.805803\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's multi_logloss: 0.667228\tvalid_1's multi_logloss: 0.805408\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.749295\tvalid_1's multi_logloss: 0.739505\n",
      "[600]\ttraining's multi_logloss: 0.666435\tvalid_1's multi_logloss: 0.711292\n",
      "[900]\ttraining's multi_logloss: 0.611828\tvalid_1's multi_logloss: 0.70387\n",
      "[1200]\ttraining's multi_logloss: 0.566132\tvalid_1's multi_logloss: 0.699064\n",
      "[1500]\ttraining's multi_logloss: 0.527141\tvalid_1's multi_logloss: 0.701827\n",
      "Early stopping, best iteration is:\n",
      "[1271]\ttraining's multi_logloss: 0.556257\tvalid_1's multi_logloss: 0.698925\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's multi_logloss: 0.746585\tvalid_1's multi_logloss: 0.806235\n",
      "[600]\ttraining's multi_logloss: 0.662702\tvalid_1's multi_logloss: 0.777828\n",
      "[900]\ttraining's multi_logloss: 0.60728\tvalid_1's multi_logloss: 0.771852\n",
      "[1200]\ttraining's multi_logloss: 0.563833\tvalid_1's multi_logloss: 0.775377\n",
      "Early stopping, best iteration is:\n",
      "[963]\ttraining's multi_logloss: 0.597553\tvalid_1's multi_logloss: 0.771493\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.741479\tvalid_1's multi_logloss: 0.887157\n",
      "[600]\ttraining's multi_logloss: 0.65728\tvalid_1's multi_logloss: 0.868705\n",
      "[900]\ttraining's multi_logloss: 0.601616\tvalid_1's multi_logloss: 0.86149\n",
      "[1200]\ttraining's multi_logloss: 0.558789\tvalid_1's multi_logloss: 0.860845\n",
      "Early stopping, best iteration is:\n",
      "[1051]\ttraining's multi_logloss: 0.578991\tvalid_1's multi_logloss: 0.859638\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.736691\tvalid_1's multi_logloss: 0.815398\n",
      "[600]\ttraining's multi_logloss: 0.653254\tvalid_1's multi_logloss: 0.798942\n",
      "[900]\ttraining's multi_logloss: 0.596989\tvalid_1's multi_logloss: 0.796336\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's multi_logloss: 0.611632\tvalid_1's multi_logloss: 0.79527\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.741007\tvalid_1's multi_logloss: 0.859478\n",
      "[600]\ttraining's multi_logloss: 0.65736\tvalid_1's multi_logloss: 0.843888\n",
      "[900]\ttraining's multi_logloss: 0.602744\tvalid_1's multi_logloss: 0.843585\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's multi_logloss: 0.617807\tvalid_1's multi_logloss: 0.842112\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.65840\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71        32\n",
      "           1       0.57      0.42      0.48       205\n",
      "           2       0.69      0.57      0.62       191\n",
      "           3       0.80      0.75      0.77       362\n",
      "           4       0.70      0.67      0.68        45\n",
      "           5       0.64      0.51      0.57       126\n",
      "           6       0.62      0.30      0.41        50\n",
      "           7       0.64      0.61      0.62       334\n",
      "           8       0.72      0.79      0.75      1305\n",
      "           9       0.82      0.85      0.83        59\n",
      "          10       0.77      0.80      0.79      1337\n",
      "\n",
      "    accuracy                           0.73      4046\n",
      "   macro avg       0.71      0.63      0.66      4046\n",
      "weighted avg       0.73      0.73      0.73      4046\n",
      "\n",
      "503 rows were filled. (confidence>0.95)\n",
      "filled test labels: [ 10   2   2 109   0   2   0   0  16  23 339]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.658236\tvalid_1's multi_logloss: 0.762093\n",
      "[600]\ttraining's multi_logloss: 0.582732\tvalid_1's multi_logloss: 0.751025\n",
      "Early stopping, best iteration is:\n",
      "[575]\ttraining's multi_logloss: 0.587499\tvalid_1's multi_logloss: 0.750799\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.661097\tvalid_1's multi_logloss: 0.807787\n",
      "[600]\ttraining's multi_logloss: 0.586884\tvalid_1's multi_logloss: 0.786003\n",
      "[900]\ttraining's multi_logloss: 0.537651\tvalid_1's multi_logloss: 0.779431\n",
      "[1200]\ttraining's multi_logloss: 0.498696\tvalid_1's multi_logloss: 0.780737\n",
      "Early stopping, best iteration is:\n",
      "[912]\ttraining's multi_logloss: 0.535862\tvalid_1's multi_logloss: 0.779162\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.675439\tvalid_1's multi_logloss: 0.730393\n",
      "[600]\ttraining's multi_logloss: 0.600298\tvalid_1's multi_logloss: 0.718623\n",
      "Early stopping, best iteration is:\n",
      "[477]\ttraining's multi_logloss: 0.625136\tvalid_1's multi_logloss: 0.717404\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.665032\tvalid_1's multi_logloss: 0.749789\n",
      "[600]\ttraining's multi_logloss: 0.589793\tvalid_1's multi_logloss: 0.726946\n",
      "[900]\ttraining's multi_logloss: 0.541296\tvalid_1's multi_logloss: 0.726394\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's multi_logloss: 0.574756\tvalid_1's multi_logloss: 0.726124\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.660975\tvalid_1's multi_logloss: 0.814295\n",
      "[600]\ttraining's multi_logloss: 0.584451\tvalid_1's multi_logloss: 0.788495\n",
      "[900]\ttraining's multi_logloss: 0.534643\tvalid_1's multi_logloss: 0.78527\n",
      "[1200]\ttraining's multi_logloss: 0.495161\tvalid_1's multi_logloss: 0.78488\n",
      "Early stopping, best iteration is:\n",
      "[1059]\ttraining's multi_logloss: 0.512937\tvalid_1's multi_logloss: 0.784084\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.667158\tvalid_1's multi_logloss: 0.693978\n",
      "[600]\ttraining's multi_logloss: 0.591158\tvalid_1's multi_logloss: 0.678446\n",
      "[900]\ttraining's multi_logloss: 0.541474\tvalid_1's multi_logloss: 0.672539\n",
      "[1200]\ttraining's multi_logloss: 0.50123\tvalid_1's multi_logloss: 0.669322\n",
      "Early stopping, best iteration is:\n",
      "[1190]\ttraining's multi_logloss: 0.50243\tvalid_1's multi_logloss: 0.669003\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.672616\tvalid_1's multi_logloss: 0.751792\n",
      "[600]\ttraining's multi_logloss: 0.59747\tvalid_1's multi_logloss: 0.729319\n",
      "[900]\ttraining's multi_logloss: 0.549596\tvalid_1's multi_logloss: 0.724219\n",
      "[1200]\ttraining's multi_logloss: 0.510527\tvalid_1's multi_logloss: 0.726178\n",
      "Early stopping, best iteration is:\n",
      "[1041]\ttraining's multi_logloss: 0.530153\tvalid_1's multi_logloss: 0.723864\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's multi_logloss: 0.67016\tvalid_1's multi_logloss: 0.655158\n",
      "[600]\ttraining's multi_logloss: 0.595247\tvalid_1's multi_logloss: 0.642053\n",
      "Early stopping, best iteration is:\n",
      "[525]\ttraining's multi_logloss: 0.609974\tvalid_1's multi_logloss: 0.641048\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.665028\tvalid_1's multi_logloss: 0.717116\n",
      "[600]\ttraining's multi_logloss: 0.59062\tvalid_1's multi_logloss: 0.696294\n",
      "[900]\ttraining's multi_logloss: 0.544234\tvalid_1's multi_logloss: 0.693347\n",
      "[1200]\ttraining's multi_logloss: 0.505902\tvalid_1's multi_logloss: 0.694107\n",
      "Early stopping, best iteration is:\n",
      "[1009]\ttraining's multi_logloss: 0.529876\tvalid_1's multi_logloss: 0.692747\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.657759\tvalid_1's multi_logloss: 0.801956\n",
      "[600]\ttraining's multi_logloss: 0.581016\tvalid_1's multi_logloss: 0.78918\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's multi_logloss: 0.584645\tvalid_1's multi_logloss: 0.788949\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.664281\tvalid_1's multi_logloss: 0.697986\n",
      "[600]\ttraining's multi_logloss: 0.589672\tvalid_1's multi_logloss: 0.672014\n",
      "[900]\ttraining's multi_logloss: 0.539976\tvalid_1's multi_logloss: 0.664634\n",
      "[1200]\ttraining's multi_logloss: 0.498874\tvalid_1's multi_logloss: 0.660859\n",
      "[1500]\ttraining's multi_logloss: 0.464258\tvalid_1's multi_logloss: 0.659408\n",
      "[1800]\ttraining's multi_logloss: 0.434905\tvalid_1's multi_logloss: 0.658018\n",
      "[2100]\ttraining's multi_logloss: 0.408153\tvalid_1's multi_logloss: 0.658331\n",
      "Early stopping, best iteration is:\n",
      "[1872]\ttraining's multi_logloss: 0.428365\tvalid_1's multi_logloss: 0.657485\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.667098\tvalid_1's multi_logloss: 0.706795\n",
      "[600]\ttraining's multi_logloss: 0.590982\tvalid_1's multi_logloss: 0.68784\n",
      "[900]\ttraining's multi_logloss: 0.542854\tvalid_1's multi_logloss: 0.68159\n",
      "[1200]\ttraining's multi_logloss: 0.503443\tvalid_1's multi_logloss: 0.674489\n",
      "[1500]\ttraining's multi_logloss: 0.469341\tvalid_1's multi_logloss: 0.672931\n",
      "[1800]\ttraining's multi_logloss: 0.439117\tvalid_1's multi_logloss: 0.672207\n",
      "[2100]\ttraining's multi_logloss: 0.411996\tvalid_1's multi_logloss: 0.673899\n",
      "Early stopping, best iteration is:\n",
      "[1839]\ttraining's multi_logloss: 0.435474\tvalid_1's multi_logloss: 0.671912\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.666931\tvalid_1's multi_logloss: 0.77076\n",
      "[600]\ttraining's multi_logloss: 0.591586\tvalid_1's multi_logloss: 0.748105\n",
      "[900]\ttraining's multi_logloss: 0.542231\tvalid_1's multi_logloss: 0.739086\n",
      "[1200]\ttraining's multi_logloss: 0.50231\tvalid_1's multi_logloss: 0.734764\n",
      "[1500]\ttraining's multi_logloss: 0.468273\tvalid_1's multi_logloss: 0.734037\n",
      "Early stopping, best iteration is:\n",
      "[1462]\ttraining's multi_logloss: 0.472302\tvalid_1's multi_logloss: 0.73357\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.655587\tvalid_1's multi_logloss: 0.809771\n",
      "[600]\ttraining's multi_logloss: 0.581436\tvalid_1's multi_logloss: 0.790289\n",
      "[900]\ttraining's multi_logloss: 0.531886\tvalid_1's multi_logloss: 0.794718\n",
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's multi_logloss: 0.567422\tvalid_1's multi_logloss: 0.789721\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.658634\tvalid_1's multi_logloss: 0.77196\n",
      "[600]\ttraining's multi_logloss: 0.584422\tvalid_1's multi_logloss: 0.750525\n",
      "[900]\ttraining's multi_logloss: 0.535275\tvalid_1's multi_logloss: 0.750706\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's multi_logloss: 0.567125\tvalid_1's multi_logloss: 0.748413\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.68214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77        42\n",
      "           1       0.59      0.42      0.49       207\n",
      "           2       0.71      0.58      0.64       193\n",
      "           3       0.85      0.82      0.84       471\n",
      "           4       0.71      0.64      0.67        45\n",
      "           5       0.61      0.52      0.56       128\n",
      "           6       0.56      0.38      0.45        50\n",
      "           7       0.63      0.60      0.61       334\n",
      "           8       0.71      0.79      0.75      1321\n",
      "           9       0.85      0.90      0.88        82\n",
      "          10       0.83      0.85      0.84      1676\n",
      "\n",
      "    accuracy                           0.76      4549\n",
      "   macro avg       0.72      0.66      0.68      4549\n",
      "weighted avg       0.76      0.76      0.76      4549\n",
      "\n",
      "450 rows were filled. (confidence>0.925)\n",
      "filled test labels: [  4   3  12  59   1   7   0   1 139  13 211]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.600977\tvalid_1's multi_logloss: 0.74219\n",
      "[600]\ttraining's multi_logloss: 0.529913\tvalid_1's multi_logloss: 0.724707\n",
      "[900]\ttraining's multi_logloss: 0.484847\tvalid_1's multi_logloss: 0.720993\n",
      "[1200]\ttraining's multi_logloss: 0.447677\tvalid_1's multi_logloss: 0.719353\n",
      "[1500]\ttraining's multi_logloss: 0.415532\tvalid_1's multi_logloss: 0.718927\n",
      "[1800]\ttraining's multi_logloss: 0.3873\tvalid_1's multi_logloss: 0.719781\n",
      "Early stopping, best iteration is:\n",
      "[1567]\ttraining's multi_logloss: 0.40891\tvalid_1's multi_logloss: 0.718308\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.606334\tvalid_1's multi_logloss: 0.627656\n",
      "[600]\ttraining's multi_logloss: 0.535714\tvalid_1's multi_logloss: 0.614663\n",
      "Early stopping, best iteration is:\n",
      "[568]\ttraining's multi_logloss: 0.541418\tvalid_1's multi_logloss: 0.614101\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.60936\tvalid_1's multi_logloss: 0.720002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's multi_logloss: 0.539611\tvalid_1's multi_logloss: 0.704327\n",
      "[900]\ttraining's multi_logloss: 0.493861\tvalid_1's multi_logloss: 0.705301\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's multi_logloss: 0.537693\tvalid_1's multi_logloss: 0.704103\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.604592\tvalid_1's multi_logloss: 0.665295\n",
      "[600]\ttraining's multi_logloss: 0.534915\tvalid_1's multi_logloss: 0.652605\n",
      "Early stopping, best iteration is:\n",
      "[535]\ttraining's multi_logloss: 0.546767\tvalid_1's multi_logloss: 0.652305\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.605827\tvalid_1's multi_logloss: 0.667285\n",
      "[600]\ttraining's multi_logloss: 0.535118\tvalid_1's multi_logloss: 0.641657\n",
      "[900]\ttraining's multi_logloss: 0.490089\tvalid_1's multi_logloss: 0.638446\n",
      "[1200]\ttraining's multi_logloss: 0.454251\tvalid_1's multi_logloss: 0.633303\n",
      "[1500]\ttraining's multi_logloss: 0.424027\tvalid_1's multi_logloss: 0.627791\n",
      "[1800]\ttraining's multi_logloss: 0.397681\tvalid_1's multi_logloss: 0.62709\n",
      "[2100]\ttraining's multi_logloss: 0.374177\tvalid_1's multi_logloss: 0.627864\n",
      "Early stopping, best iteration is:\n",
      "[1848]\ttraining's multi_logloss: 0.39371\tvalid_1's multi_logloss: 0.626718\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.607433\tvalid_1's multi_logloss: 0.696993\n",
      "[600]\ttraining's multi_logloss: 0.537411\tvalid_1's multi_logloss: 0.668047\n",
      "[900]\ttraining's multi_logloss: 0.492601\tvalid_1's multi_logloss: 0.666372\n",
      "Early stopping, best iteration is:\n",
      "[706]\ttraining's multi_logloss: 0.520131\tvalid_1's multi_logloss: 0.66606\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.614686\tvalid_1's multi_logloss: 0.646042\n",
      "[600]\ttraining's multi_logloss: 0.545295\tvalid_1's multi_logloss: 0.628038\n",
      "[900]\ttraining's multi_logloss: 0.500836\tvalid_1's multi_logloss: 0.635025\n",
      "Early stopping, best iteration is:\n",
      "[601]\ttraining's multi_logloss: 0.545117\tvalid_1's multi_logloss: 0.627897\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.597368\tvalid_1's multi_logloss: 0.743748\n",
      "[600]\ttraining's multi_logloss: 0.527743\tvalid_1's multi_logloss: 0.730366\n",
      "[900]\ttraining's multi_logloss: 0.482575\tvalid_1's multi_logloss: 0.731117\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's multi_logloss: 0.515174\tvalid_1's multi_logloss: 0.729419\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.610693\tvalid_1's multi_logloss: 0.643379\n",
      "[600]\ttraining's multi_logloss: 0.539715\tvalid_1's multi_logloss: 0.622856\n",
      "[900]\ttraining's multi_logloss: 0.493909\tvalid_1's multi_logloss: 0.621569\n",
      "Early stopping, best iteration is:\n",
      "[785]\ttraining's multi_logloss: 0.509694\tvalid_1's multi_logloss: 0.620281\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.604952\tvalid_1's multi_logloss: 0.670872\n",
      "[600]\ttraining's multi_logloss: 0.533812\tvalid_1's multi_logloss: 0.661219\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttraining's multi_logloss: 0.541066\tvalid_1's multi_logloss: 0.660682\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.605479\tvalid_1's multi_logloss: 0.692198\n",
      "[600]\ttraining's multi_logloss: 0.53555\tvalid_1's multi_logloss: 0.66543\n",
      "[900]\ttraining's multi_logloss: 0.489152\tvalid_1's multi_logloss: 0.663759\n",
      "[1200]\ttraining's multi_logloss: 0.452621\tvalid_1's multi_logloss: 0.662553\n",
      "Early stopping, best iteration is:\n",
      "[1192]\ttraining's multi_logloss: 0.453514\tvalid_1's multi_logloss: 0.662489\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.605733\tvalid_1's multi_logloss: 0.711402\n",
      "[600]\ttraining's multi_logloss: 0.534126\tvalid_1's multi_logloss: 0.68947\n",
      "[900]\ttraining's multi_logloss: 0.488266\tvalid_1's multi_logloss: 0.683736\n",
      "[1200]\ttraining's multi_logloss: 0.452053\tvalid_1's multi_logloss: 0.679533\n",
      "[1500]\ttraining's multi_logloss: 0.421512\tvalid_1's multi_logloss: 0.675636\n",
      "[1800]\ttraining's multi_logloss: 0.394205\tvalid_1's multi_logloss: 0.673534\n",
      "Early stopping, best iteration is:\n",
      "[1777]\ttraining's multi_logloss: 0.396197\tvalid_1's multi_logloss: 0.673362\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.61467\tvalid_1's multi_logloss: 0.704446\n",
      "[600]\ttraining's multi_logloss: 0.543631\tvalid_1's multi_logloss: 0.680405\n",
      "[900]\ttraining's multi_logloss: 0.49832\tvalid_1's multi_logloss: 0.682587\n",
      "Early stopping, best iteration is:\n",
      "[716]\ttraining's multi_logloss: 0.524355\tvalid_1's multi_logloss: 0.679826\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.603687\tvalid_1's multi_logloss: 0.662338\n",
      "[600]\ttraining's multi_logloss: 0.532727\tvalid_1's multi_logloss: 0.633745\n",
      "[900]\ttraining's multi_logloss: 0.487421\tvalid_1's multi_logloss: 0.624194\n",
      "[1200]\ttraining's multi_logloss: 0.451727\tvalid_1's multi_logloss: 0.620809\n",
      "Early stopping, best iteration is:\n",
      "[1194]\ttraining's multi_logloss: 0.45237\tvalid_1's multi_logloss: 0.620639\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.606861\tvalid_1's multi_logloss: 0.681749\n",
      "[600]\ttraining's multi_logloss: 0.538912\tvalid_1's multi_logloss: 0.651541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's multi_logloss: 0.4926\tvalid_1's multi_logloss: 0.647373\n",
      "[1200]\ttraining's multi_logloss: 0.455787\tvalid_1's multi_logloss: 0.648319\n",
      "Early stopping, best iteration is:\n",
      "[997]\ttraining's multi_logloss: 0.479949\tvalid_1's multi_logloss: 0.646665\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.69966\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        46\n",
      "           1       0.57      0.43      0.49       210\n",
      "           2       0.74      0.60      0.66       205\n",
      "           3       0.87      0.84      0.86       530\n",
      "           4       0.70      0.57      0.63        46\n",
      "           5       0.63      0.56      0.60       135\n",
      "           6       0.53      0.36      0.43        50\n",
      "           7       0.67      0.62      0.64       335\n",
      "           8       0.75      0.82      0.78      1460\n",
      "           9       0.93      0.92      0.92        95\n",
      "          10       0.85      0.86      0.86      1887\n",
      "\n",
      "    accuracy                           0.79      4999\n",
      "   macro avg       0.74      0.67      0.70      4999\n",
      "weighted avg       0.79      0.79      0.79      4999\n",
      "\n",
      "400 rows were filled. (confidence>0.9)\n",
      "filled test labels: [  3   2  13  48   4  10   1   5 193   3 118]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.564573\tvalid_1's multi_logloss: 0.637398\n",
      "[600]\ttraining's multi_logloss: 0.497456\tvalid_1's multi_logloss: 0.621698\n",
      "[900]\ttraining's multi_logloss: 0.454165\tvalid_1's multi_logloss: 0.616559\n",
      "[1200]\ttraining's multi_logloss: 0.419781\tvalid_1's multi_logloss: 0.61431\n",
      "[1500]\ttraining's multi_logloss: 0.391098\tvalid_1's multi_logloss: 0.613131\n",
      "[1800]\ttraining's multi_logloss: 0.365959\tvalid_1's multi_logloss: 0.613561\n",
      "Early stopping, best iteration is:\n",
      "[1653]\ttraining's multi_logloss: 0.377734\tvalid_1's multi_logloss: 0.612801\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.56732\tvalid_1's multi_logloss: 0.674609\n",
      "[600]\ttraining's multi_logloss: 0.502094\tvalid_1's multi_logloss: 0.659405\n",
      "[900]\ttraining's multi_logloss: 0.460431\tvalid_1's multi_logloss: 0.659182\n",
      "Early stopping, best iteration is:\n",
      "[803]\ttraining's multi_logloss: 0.47274\tvalid_1's multi_logloss: 0.658535\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.569597\tvalid_1's multi_logloss: 0.579107\n",
      "[600]\ttraining's multi_logloss: 0.503557\tvalid_1's multi_logloss: 0.560592\n",
      "[900]\ttraining's multi_logloss: 0.462205\tvalid_1's multi_logloss: 0.559417\n",
      "Early stopping, best iteration is:\n",
      "[788]\ttraining's multi_logloss: 0.476168\tvalid_1's multi_logloss: 0.55861\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.558989\tvalid_1's multi_logloss: 0.6877\n",
      "[600]\ttraining's multi_logloss: 0.492271\tvalid_1's multi_logloss: 0.672154\n",
      "[900]\ttraining's multi_logloss: 0.451609\tvalid_1's multi_logloss: 0.673067\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's multi_logloss: 0.477885\tvalid_1's multi_logloss: 0.671448\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.569899\tvalid_1's multi_logloss: 0.57233\n",
      "[600]\ttraining's multi_logloss: 0.504609\tvalid_1's multi_logloss: 0.549508\n",
      "[900]\ttraining's multi_logloss: 0.462351\tvalid_1's multi_logloss: 0.551984\n",
      "Early stopping, best iteration is:\n",
      "[604]\ttraining's multi_logloss: 0.503953\tvalid_1's multi_logloss: 0.549271\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.563748\tvalid_1's multi_logloss: 0.632189\n",
      "[600]\ttraining's multi_logloss: 0.496639\tvalid_1's multi_logloss: 0.60941\n",
      "[900]\ttraining's multi_logloss: 0.454531\tvalid_1's multi_logloss: 0.609132\n",
      "Early stopping, best iteration is:\n",
      "[711]\ttraining's multi_logloss: 0.479652\tvalid_1's multi_logloss: 0.608484\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.563656\tvalid_1's multi_logloss: 0.687927\n",
      "[600]\ttraining's multi_logloss: 0.49875\tvalid_1's multi_logloss: 0.66718\n",
      "[900]\ttraining's multi_logloss: 0.456957\tvalid_1's multi_logloss: 0.664546\n",
      "[1200]\ttraining's multi_logloss: 0.422763\tvalid_1's multi_logloss: 0.662721\n",
      "[1500]\ttraining's multi_logloss: 0.393796\tvalid_1's multi_logloss: 0.662737\n",
      "Early stopping, best iteration is:\n",
      "[1391]\ttraining's multi_logloss: 0.403799\tvalid_1's multi_logloss: 0.662177\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.559672\tvalid_1's multi_logloss: 0.662344\n",
      "[600]\ttraining's multi_logloss: 0.494156\tvalid_1's multi_logloss: 0.644354\n",
      "[900]\ttraining's multi_logloss: 0.452495\tvalid_1's multi_logloss: 0.637521\n",
      "[1200]\ttraining's multi_logloss: 0.418207\tvalid_1's multi_logloss: 0.635184\n",
      "[1500]\ttraining's multi_logloss: 0.389285\tvalid_1's multi_logloss: 0.633169\n",
      "[1800]\ttraining's multi_logloss: 0.363632\tvalid_1's multi_logloss: 0.629105\n",
      "[2100]\ttraining's multi_logloss: 0.340905\tvalid_1's multi_logloss: 0.628292\n",
      "Early stopping, best iteration is:\n",
      "[1965]\ttraining's multi_logloss: 0.350917\tvalid_1's multi_logloss: 0.627682\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.569085\tvalid_1's multi_logloss: 0.624653\n",
      "[600]\ttraining's multi_logloss: 0.502985\tvalid_1's multi_logloss: 0.601898\n",
      "[900]\ttraining's multi_logloss: 0.461909\tvalid_1's multi_logloss: 0.594712\n",
      "[1200]\ttraining's multi_logloss: 0.427934\tvalid_1's multi_logloss: 0.591042\n",
      "[1500]\ttraining's multi_logloss: 0.398753\tvalid_1's multi_logloss: 0.588938\n",
      "Early stopping, best iteration is:\n",
      "[1412]\ttraining's multi_logloss: 0.407055\tvalid_1's multi_logloss: 0.588534\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.566954\tvalid_1's multi_logloss: 0.591208\n",
      "[600]\ttraining's multi_logloss: 0.499912\tvalid_1's multi_logloss: 0.588455\n",
      "Early stopping, best iteration is:\n",
      "[558]\ttraining's multi_logloss: 0.506819\tvalid_1's multi_logloss: 0.587767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.56045\tvalid_1's multi_logloss: 0.697882\n",
      "[600]\ttraining's multi_logloss: 0.494869\tvalid_1's multi_logloss: 0.679078\n",
      "[900]\ttraining's multi_logloss: 0.452354\tvalid_1's multi_logloss: 0.684753\n",
      "Early stopping, best iteration is:\n",
      "[609]\ttraining's multi_logloss: 0.493474\tvalid_1's multi_logloss: 0.678654\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.562488\tvalid_1's multi_logloss: 0.634791\n",
      "[600]\ttraining's multi_logloss: 0.496791\tvalid_1's multi_logloss: 0.625479\n",
      "Early stopping, best iteration is:\n",
      "[523]\ttraining's multi_logloss: 0.510082\tvalid_1's multi_logloss: 0.625052\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.563766\tvalid_1's multi_logloss: 0.624167\n",
      "[600]\ttraining's multi_logloss: 0.498786\tvalid_1's multi_logloss: 0.610115\n",
      "[900]\ttraining's multi_logloss: 0.458212\tvalid_1's multi_logloss: 0.606097\n",
      "[1200]\ttraining's multi_logloss: 0.424602\tvalid_1's multi_logloss: 0.604466\n",
      "[1500]\ttraining's multi_logloss: 0.396025\tvalid_1's multi_logloss: 0.604213\n",
      "[1800]\ttraining's multi_logloss: 0.37065\tvalid_1's multi_logloss: 0.604821\n",
      "Early stopping, best iteration is:\n",
      "[1605]\ttraining's multi_logloss: 0.386705\tvalid_1's multi_logloss: 0.603591\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.563262\tvalid_1's multi_logloss: 0.659979\n",
      "[600]\ttraining's multi_logloss: 0.496816\tvalid_1's multi_logloss: 0.652658\n",
      "Early stopping, best iteration is:\n",
      "[465]\ttraining's multi_logloss: 0.521467\tvalid_1's multi_logloss: 0.650108\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.559703\tvalid_1's multi_logloss: 0.647817\n",
      "[600]\ttraining's multi_logloss: 0.495388\tvalid_1's multi_logloss: 0.624692\n",
      "[900]\ttraining's multi_logloss: 0.453171\tvalid_1's multi_logloss: 0.624072\n",
      "Early stopping, best iteration is:\n",
      "[770]\ttraining's multi_logloss: 0.470101\tvalid_1's multi_logloss: 0.623372\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.71566\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81        49\n",
      "           1       0.58      0.48      0.52       212\n",
      "           2       0.75      0.61      0.67       218\n",
      "           3       0.89      0.86      0.87       578\n",
      "           4       0.72      0.58      0.64        50\n",
      "           5       0.69      0.56      0.62       145\n",
      "           6       0.71      0.39      0.51        51\n",
      "           7       0.66      0.64      0.65       340\n",
      "           8       0.78      0.84      0.81      1653\n",
      "           9       0.91      0.90      0.90        98\n",
      "          10       0.85      0.87      0.86      2005\n",
      "\n",
      "    accuracy                           0.80      5399\n",
      "   macro avg       0.76      0.68      0.72      5399\n",
      "weighted avg       0.80      0.80      0.80      5399\n",
      "\n",
      "317 rows were filled. (confidence>0.875)\n",
      "filled test labels: [  3   5   4  29   4   4   0  19 175   1  73]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.539162\tvalid_1's multi_logloss: 0.547833\n",
      "[600]\ttraining's multi_logloss: 0.475987\tvalid_1's multi_logloss: 0.521425\n",
      "[900]\ttraining's multi_logloss: 0.435145\tvalid_1's multi_logloss: 0.511559\n",
      "[1200]\ttraining's multi_logloss: 0.403046\tvalid_1's multi_logloss: 0.50551\n",
      "[1500]\ttraining's multi_logloss: 0.375667\tvalid_1's multi_logloss: 0.503384\n",
      "[1800]\ttraining's multi_logloss: 0.351489\tvalid_1's multi_logloss: 0.504474\n",
      "Early stopping, best iteration is:\n",
      "[1524]\ttraining's multi_logloss: 0.37354\tvalid_1's multi_logloss: 0.503092\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.539169\tvalid_1's multi_logloss: 0.595146\n",
      "[600]\ttraining's multi_logloss: 0.477293\tvalid_1's multi_logloss: 0.583397\n",
      "[900]\ttraining's multi_logloss: 0.438673\tvalid_1's multi_logloss: 0.583885\n",
      "Early stopping, best iteration is:\n",
      "[747]\ttraining's multi_logloss: 0.45737\tvalid_1's multi_logloss: 0.582961\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.545162\tvalid_1's multi_logloss: 0.552584\n",
      "[600]\ttraining's multi_logloss: 0.482448\tvalid_1's multi_logloss: 0.537099\n",
      "[900]\ttraining's multi_logloss: 0.442898\tvalid_1's multi_logloss: 0.534162\n",
      "[1200]\ttraining's multi_logloss: 0.41085\tvalid_1's multi_logloss: 0.535475\n",
      "Early stopping, best iteration is:\n",
      "[1033]\ttraining's multi_logloss: 0.427848\tvalid_1's multi_logloss: 0.533786\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.534118\tvalid_1's multi_logloss: 0.657923\n",
      "[600]\ttraining's multi_logloss: 0.471034\tvalid_1's multi_logloss: 0.64463\n",
      "[900]\ttraining's multi_logloss: 0.431879\tvalid_1's multi_logloss: 0.646889\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's multi_logloss: 0.466093\tvalid_1's multi_logloss: 0.644153\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.537532\tvalid_1's multi_logloss: 0.576188\n",
      "[600]\ttraining's multi_logloss: 0.474603\tvalid_1's multi_logloss: 0.550483\n",
      "[900]\ttraining's multi_logloss: 0.433036\tvalid_1's multi_logloss: 0.546457\n",
      "[1200]\ttraining's multi_logloss: 0.400404\tvalid_1's multi_logloss: 0.544765\n",
      "Early stopping, best iteration is:\n",
      "[1107]\ttraining's multi_logloss: 0.410004\tvalid_1's multi_logloss: 0.544341\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.532522\tvalid_1's multi_logloss: 0.671741\n",
      "[600]\ttraining's multi_logloss: 0.469603\tvalid_1's multi_logloss: 0.657893\n",
      "[900]\ttraining's multi_logloss: 0.428844\tvalid_1's multi_logloss: 0.658454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[676]\ttraining's multi_logloss: 0.458154\tvalid_1's multi_logloss: 0.657114\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.533485\tvalid_1's multi_logloss: 0.681105\n",
      "[600]\ttraining's multi_logloss: 0.471381\tvalid_1's multi_logloss: 0.665215\n",
      "[900]\ttraining's multi_logloss: 0.432243\tvalid_1's multi_logloss: 0.65991\n",
      "[1200]\ttraining's multi_logloss: 0.400831\tvalid_1's multi_logloss: 0.659146\n",
      "[1500]\ttraining's multi_logloss: 0.374489\tvalid_1's multi_logloss: 0.657927\n",
      "[1800]\ttraining's multi_logloss: 0.351772\tvalid_1's multi_logloss: 0.660181\n",
      "Early stopping, best iteration is:\n",
      "[1528]\ttraining's multi_logloss: 0.372301\tvalid_1's multi_logloss: 0.657819\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.532453\tvalid_1's multi_logloss: 0.673458\n",
      "[600]\ttraining's multi_logloss: 0.470046\tvalid_1's multi_logloss: 0.662875\n",
      "[900]\ttraining's multi_logloss: 0.42992\tvalid_1's multi_logloss: 0.661731\n",
      "[1200]\ttraining's multi_logloss: 0.397437\tvalid_1's multi_logloss: 0.660143\n",
      "Early stopping, best iteration is:\n",
      "[1142]\ttraining's multi_logloss: 0.40317\tvalid_1's multi_logloss: 0.65964\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.541121\tvalid_1's multi_logloss: 0.61714\n",
      "[600]\ttraining's multi_logloss: 0.477463\tvalid_1's multi_logloss: 0.604865\n",
      "Early stopping, best iteration is:\n",
      "[541]\ttraining's multi_logloss: 0.486924\tvalid_1's multi_logloss: 0.604393\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.531174\tvalid_1's multi_logloss: 0.65176\n",
      "[600]\ttraining's multi_logloss: 0.46908\tvalid_1's multi_logloss: 0.63116\n",
      "[900]\ttraining's multi_logloss: 0.428466\tvalid_1's multi_logloss: 0.62739\n",
      "Early stopping, best iteration is:\n",
      "[863]\ttraining's multi_logloss: 0.432903\tvalid_1's multi_logloss: 0.627098\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.543533\tvalid_1's multi_logloss: 0.51092\n",
      "[600]\ttraining's multi_logloss: 0.481293\tvalid_1's multi_logloss: 0.478987\n",
      "[900]\ttraining's multi_logloss: 0.440696\tvalid_1's multi_logloss: 0.472609\n",
      "[1200]\ttraining's multi_logloss: 0.407892\tvalid_1's multi_logloss: 0.473361\n",
      "Early stopping, best iteration is:\n",
      "[1015]\ttraining's multi_logloss: 0.42762\tvalid_1's multi_logloss: 0.471709\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.537881\tvalid_1's multi_logloss: 0.54976\n",
      "[600]\ttraining's multi_logloss: 0.475786\tvalid_1's multi_logloss: 0.52768\n",
      "[900]\ttraining's multi_logloss: 0.436156\tvalid_1's multi_logloss: 0.522689\n",
      "[1200]\ttraining's multi_logloss: 0.40333\tvalid_1's multi_logloss: 0.521217\n",
      "Early stopping, best iteration is:\n",
      "[1088]\ttraining's multi_logloss: 0.414898\tvalid_1's multi_logloss: 0.521053\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.533063\tvalid_1's multi_logloss: 0.635511\n",
      "[600]\ttraining's multi_logloss: 0.469166\tvalid_1's multi_logloss: 0.612343\n",
      "[900]\ttraining's multi_logloss: 0.428312\tvalid_1's multi_logloss: 0.612484\n",
      "Early stopping, best iteration is:\n",
      "[692]\ttraining's multi_logloss: 0.455589\tvalid_1's multi_logloss: 0.611296\n",
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.530497\tvalid_1's multi_logloss: 0.651145\n",
      "[600]\ttraining's multi_logloss: 0.46846\tvalid_1's multi_logloss: 0.631924\n",
      "[900]\ttraining's multi_logloss: 0.428738\tvalid_1's multi_logloss: 0.624916\n",
      "[1200]\ttraining's multi_logloss: 0.395953\tvalid_1's multi_logloss: 0.616565\n",
      "[1500]\ttraining's multi_logloss: 0.36793\tvalid_1's multi_logloss: 0.615183\n",
      "[1800]\ttraining's multi_logloss: 0.343419\tvalid_1's multi_logloss: 0.617593\n",
      "Early stopping, best iteration is:\n",
      "[1611]\ttraining's multi_logloss: 0.358402\tvalid_1's multi_logloss: 0.615019\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.538596\tvalid_1's multi_logloss: 0.581789\n",
      "[600]\ttraining's multi_logloss: 0.475148\tvalid_1's multi_logloss: 0.5616\n",
      "[900]\ttraining's multi_logloss: 0.435129\tvalid_1's multi_logloss: 0.562311\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's multi_logloss: 0.469338\tvalid_1's multi_logloss: 0.561181\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.71747\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82        52\n",
      "           1       0.57      0.43      0.49       217\n",
      "           2       0.76      0.61      0.68       222\n",
      "           3       0.89      0.86      0.87       607\n",
      "           4       0.74      0.59      0.66        54\n",
      "           5       0.69      0.62      0.65       149\n",
      "           6       0.63      0.37      0.47        51\n",
      "           7       0.66      0.63      0.64       359\n",
      "           8       0.80      0.85      0.82      1828\n",
      "           9       0.93      0.90      0.91        99\n",
      "          10       0.86      0.88      0.87      2078\n",
      "\n",
      "    accuracy                           0.81      5716\n",
      "   macro avg       0.76      0.69      0.72      5716\n",
      "weighted avg       0.81      0.81      0.81      5716\n",
      "\n",
      "252 rows were filled. (confidence>0.85)\n",
      "filled test labels: [  0   3   8  20   1   8   2  24 122   3  61]\n",
      "\n",
      "\n",
      "------------------------------ fold 0 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.521541\tvalid_1's multi_logloss: 0.552842\n",
      "[600]\ttraining's multi_logloss: 0.460489\tvalid_1's multi_logloss: 0.535495\n",
      "[900]\ttraining's multi_logloss: 0.421198\tvalid_1's multi_logloss: 0.532462\n",
      "[1200]\ttraining's multi_logloss: 0.389215\tvalid_1's multi_logloss: 0.533136\n",
      "Early stopping, best iteration is:\n",
      "[1069]\ttraining's multi_logloss: 0.40224\tvalid_1's multi_logloss: 0.532008\n",
      "\n",
      "------------------------------ fold 1 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's multi_logloss: 0.519182\tvalid_1's multi_logloss: 0.591705\n",
      "[600]\ttraining's multi_logloss: 0.456949\tvalid_1's multi_logloss: 0.58053\n",
      "Early stopping, best iteration is:\n",
      "[569]\ttraining's multi_logloss: 0.46163\tvalid_1's multi_logloss: 0.580153\n",
      "\n",
      "------------------------------ fold 2 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.525215\tvalid_1's multi_logloss: 0.587067\n",
      "[600]\ttraining's multi_logloss: 0.464176\tvalid_1's multi_logloss: 0.57183\n",
      "[900]\ttraining's multi_logloss: 0.426466\tvalid_1's multi_logloss: 0.566383\n",
      "[1200]\ttraining's multi_logloss: 0.39511\tvalid_1's multi_logloss: 0.564762\n",
      "[1500]\ttraining's multi_logloss: 0.368981\tvalid_1's multi_logloss: 0.564097\n",
      "Early stopping, best iteration is:\n",
      "[1371]\ttraining's multi_logloss: 0.379617\tvalid_1's multi_logloss: 0.563521\n",
      "\n",
      "------------------------------ fold 3 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.515843\tvalid_1's multi_logloss: 0.622299\n",
      "[600]\ttraining's multi_logloss: 0.454577\tvalid_1's multi_logloss: 0.59573\n",
      "[900]\ttraining's multi_logloss: 0.416353\tvalid_1's multi_logloss: 0.588599\n",
      "[1200]\ttraining's multi_logloss: 0.386133\tvalid_1's multi_logloss: 0.587332\n",
      "Early stopping, best iteration is:\n",
      "[1154]\ttraining's multi_logloss: 0.390492\tvalid_1's multi_logloss: 0.587119\n",
      "\n",
      "------------------------------ fold 4 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.521801\tvalid_1's multi_logloss: 0.588792\n",
      "[600]\ttraining's multi_logloss: 0.460911\tvalid_1's multi_logloss: 0.576997\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttraining's multi_logloss: 0.466877\tvalid_1's multi_logloss: 0.576636\n",
      "\n",
      "------------------------------ fold 5 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.51257\tvalid_1's multi_logloss: 0.657303\n",
      "[600]\ttraining's multi_logloss: 0.450618\tvalid_1's multi_logloss: 0.6535\n",
      "Early stopping, best iteration is:\n",
      "[462]\ttraining's multi_logloss: 0.47433\tvalid_1's multi_logloss: 0.650519\n",
      "\n",
      "------------------------------ fold 6 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.525496\tvalid_1's multi_logloss: 0.58052\n",
      "[600]\ttraining's multi_logloss: 0.464755\tvalid_1's multi_logloss: 0.566755\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's multi_logloss: 0.470732\tvalid_1's multi_logloss: 0.566535\n",
      "\n",
      "------------------------------ fold 7 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.512029\tvalid_1's multi_logloss: 0.64883\n",
      "[600]\ttraining's multi_logloss: 0.451618\tvalid_1's multi_logloss: 0.637225\n",
      "[900]\ttraining's multi_logloss: 0.41385\tvalid_1's multi_logloss: 0.636439\n",
      "[1200]\ttraining's multi_logloss: 0.383514\tvalid_1's multi_logloss: 0.636939\n",
      "Early stopping, best iteration is:\n",
      "[997]\ttraining's multi_logloss: 0.403394\tvalid_1's multi_logloss: 0.635926\n",
      "\n",
      "------------------------------ fold 8 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.524107\tvalid_1's multi_logloss: 0.538535\n",
      "[600]\ttraining's multi_logloss: 0.463459\tvalid_1's multi_logloss: 0.518674\n",
      "[900]\ttraining's multi_logloss: 0.425119\tvalid_1's multi_logloss: 0.51492\n",
      "[1200]\ttraining's multi_logloss: 0.394132\tvalid_1's multi_logloss: 0.511099\n",
      "[1500]\ttraining's multi_logloss: 0.367688\tvalid_1's multi_logloss: 0.507397\n",
      "[1800]\ttraining's multi_logloss: 0.345061\tvalid_1's multi_logloss: 0.506079\n",
      "[2100]\ttraining's multi_logloss: 0.324333\tvalid_1's multi_logloss: 0.506125\n",
      "Early stopping, best iteration is:\n",
      "[1935]\ttraining's multi_logloss: 0.335431\tvalid_1's multi_logloss: 0.505621\n",
      "\n",
      "------------------------------ fold 9 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.515361\tvalid_1's multi_logloss: 0.637741\n",
      "[600]\ttraining's multi_logloss: 0.454238\tvalid_1's multi_logloss: 0.617056\n",
      "[900]\ttraining's multi_logloss: 0.414432\tvalid_1's multi_logloss: 0.613165\n",
      "[1200]\ttraining's multi_logloss: 0.382858\tvalid_1's multi_logloss: 0.612199\n",
      "Early stopping, best iteration is:\n",
      "[1163]\ttraining's multi_logloss: 0.386363\tvalid_1's multi_logloss: 0.611757\n",
      "\n",
      "------------------------------ fold 10 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.522006\tvalid_1's multi_logloss: 0.584658\n",
      "[600]\ttraining's multi_logloss: 0.462297\tvalid_1's multi_logloss: 0.546073\n",
      "[900]\ttraining's multi_logloss: 0.423744\tvalid_1's multi_logloss: 0.538325\n",
      "[1200]\ttraining's multi_logloss: 0.392814\tvalid_1's multi_logloss: 0.537144\n",
      "[1500]\ttraining's multi_logloss: 0.367049\tvalid_1's multi_logloss: 0.53795\n",
      "Early stopping, best iteration is:\n",
      "[1206]\ttraining's multi_logloss: 0.392264\tvalid_1's multi_logloss: 0.536829\n",
      "\n",
      "------------------------------ fold 11 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.519798\tvalid_1's multi_logloss: 0.550426\n",
      "[600]\ttraining's multi_logloss: 0.459777\tvalid_1's multi_logloss: 0.522984\n",
      "[900]\ttraining's multi_logloss: 0.420892\tvalid_1's multi_logloss: 0.515867\n",
      "[1200]\ttraining's multi_logloss: 0.390115\tvalid_1's multi_logloss: 0.511617\n",
      "[1500]\ttraining's multi_logloss: 0.363688\tvalid_1's multi_logloss: 0.507676\n",
      "[1800]\ttraining's multi_logloss: 0.341103\tvalid_1's multi_logloss: 0.506292\n",
      "[2100]\ttraining's multi_logloss: 0.320683\tvalid_1's multi_logloss: 0.506335\n",
      "Early stopping, best iteration is:\n",
      "[1859]\ttraining's multi_logloss: 0.336936\tvalid_1's multi_logloss: 0.506039\n",
      "\n",
      "------------------------------ fold 12 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.52461\tvalid_1's multi_logloss: 0.536575\n",
      "[600]\ttraining's multi_logloss: 0.46206\tvalid_1's multi_logloss: 0.516533\n",
      "[900]\ttraining's multi_logloss: 0.423038\tvalid_1's multi_logloss: 0.508083\n",
      "[1200]\ttraining's multi_logloss: 0.391216\tvalid_1's multi_logloss: 0.504161\n",
      "[1500]\ttraining's multi_logloss: 0.364747\tvalid_1's multi_logloss: 0.505713\n",
      "Early stopping, best iteration is:\n",
      "[1332]\ttraining's multi_logloss: 0.379154\tvalid_1's multi_logloss: 0.503648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------ fold 13 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.519716\tvalid_1's multi_logloss: 0.542601\n",
      "[600]\ttraining's multi_logloss: 0.459083\tvalid_1's multi_logloss: 0.525966\n",
      "[900]\ttraining's multi_logloss: 0.420859\tvalid_1's multi_logloss: 0.528265\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's multi_logloss: 0.454283\tvalid_1's multi_logloss: 0.525719\n",
      "\n",
      "------------------------------ fold 14 ------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[300]\ttraining's multi_logloss: 0.51113\tvalid_1's multi_logloss: 0.632208\n",
      "[600]\ttraining's multi_logloss: 0.451277\tvalid_1's multi_logloss: 0.615968\n",
      "[900]\ttraining's multi_logloss: 0.412303\tvalid_1's multi_logloss: 0.614529\n",
      "Early stopping, best iteration is:\n",
      "[753]\ttraining's multi_logloss: 0.429985\tvalid_1's multi_logloss: 0.614\n",
      "\n",
      "CV score (not reliable!)\n",
      "  f1:  0.72708\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81        52\n",
      "           1       0.62      0.47      0.53       220\n",
      "           2       0.81      0.60      0.69       230\n",
      "           3       0.89      0.87      0.88       627\n",
      "           4       0.76      0.62      0.68        55\n",
      "           5       0.71      0.62      0.66       157\n",
      "           6       0.61      0.36      0.45        53\n",
      "           7       0.70      0.67      0.68       383\n",
      "           8       0.81      0.86      0.83      1950\n",
      "           9       0.91      0.90      0.91       102\n",
      "          10       0.86      0.89      0.87      2139\n",
      "\n",
      "    accuracy                           0.82      5968\n",
      "   macro avg       0.78      0.69      0.73      5968\n",
      "weighted avg       0.82      0.82      0.82      5968\n",
      "\n",
      "2124 rows were filled. (confidence>-inf)\n",
      "filled test labels: [  9 137  85 111  26  66  35 264 792  12 587]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pseudo_labeling_threshold in [0.95, 0.925, 0.9, 0.875, 0.85, -np.inf]:\n",
    "    df = df_main.copy()\n",
    "    \n",
    "    \n",
    "    # feature engineering\n",
    "\n",
    "    df[\"genre_name\"] = df[\"genre\"].map(dict(df_genre_labels[[\"labels\", \"genre\"]].values))\n",
    "\n",
    "    df[\"tempo\"] = df[\"tempo\"].map(lambda x: sum(map(int, x.split(\"-\"))) / 2)\n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"region\"]).rename(columns={\"unknown\": \"region_unknown\"})], axis=1)\n",
    "\n",
    "    df[\"num_nans\"] = 0\n",
    "    for col in [\n",
    "        \"acousticness\",\n",
    "        \"positiveness\",\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"liveness\",\n",
    "        \"speechiness\",\n",
    "        \"instrumentalness\",\n",
    "    ]:\n",
    "        df[\"num_nans\"] += df[col].isna()\n",
    "\n",
    "    class CountEncoder:\n",
    "        def fit(self, series):\n",
    "            self.counts = series.groupby(series).count()\n",
    "            return self\n",
    "\n",
    "        def transform(self, series):\n",
    "            return series.map(self.counts).fillna(0)\n",
    "\n",
    "        def fit_transform(self, series):\n",
    "            return self.fit(series).transform(series)\n",
    "    columns_count_enc = [\"region\"]\n",
    "    for col in columns_count_enc:\n",
    "        df[\"countenc_\" + col] = CountEncoder().fit_transform(df[col])\n",
    "        df.loc[df[col].isna().values, \"countenc_\" + col] = np.nan\n",
    "\n",
    "\n",
    "    columns_label_enc = [\"region\"]\n",
    "    for col in columns_count_enc:\n",
    "        df[\"labelenc_\" + col] = LabelEncoder().fit_transform(df[col])\n",
    "        df.loc[df[col].isna().values, \"labelenc_\" + col] = np.nan\n",
    "\n",
    "\n",
    "    class GroupFeatureExtractor:  # 参考: https://signate.jp/competitions/449/discussions/lgbm-baseline-lb06240\n",
    "        EX_TRANS_METHODS = [\"deviation\", \"zscore\"]\n",
    "\n",
    "        def __init__(self, group_key, group_values, agg_methods):\n",
    "            self.group_key = group_key\n",
    "            self.group_values = group_values\n",
    "\n",
    "            self.ex_trans_methods = [m for m in agg_methods if m in self.EX_TRANS_METHODS]\n",
    "            self.agg_methods = [m for m in agg_methods if m not in self.ex_trans_methods]\n",
    "            self.df_agg = None\n",
    "\n",
    "        def fit(self, df_train, y=None):\n",
    "            if not self.agg_methods:\n",
    "                return\n",
    "            dfs = []\n",
    "            for agg_method in self.agg_methods:\n",
    "                if callable(agg_method):\n",
    "                    agg_method_name = agg_method.__name__\n",
    "                else:\n",
    "                    agg_method_name = agg_method\n",
    "                df_agg = (df_train[[self.group_key] + self.group_values].groupby(self.group_key).agg(agg_method))\n",
    "                df_agg.columns = self._get_column_names(agg_method_name)\n",
    "                dfs.append(df_agg)\n",
    "            self.df_agg = pd.concat(dfs, axis=1).reset_index()\n",
    "\n",
    "        def transform(self, df_eval):\n",
    "            key = self.group_key\n",
    "            if self.agg_methods:\n",
    "                df_features = pd.merge(df_eval[[self.group_key]], self.df_agg, on=self.group_key, how=\"left\")\n",
    "            else:\n",
    "                df_features = df_eval[[self.group_key]].copy()\n",
    "            if self.ex_trans_methods:\n",
    "                if \"deviation\" in self.ex_trans_methods:\n",
    "                    df_features[self._get_agg_column_names(\"deviation\")] = df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform(\"mean\")\n",
    "                if \"zscore\" in self.ex_trans_methods:\n",
    "                    df_features[self._get_column_names(\"zscore\")] = (df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform(\"mean\")) \\\n",
    "                                                                    / (df_eval[[key]+self.group_values].groupby(key).transform(\"std\") + 1e-8)\n",
    "            df_features.drop(self.group_key, axis=1, inplace=True)\n",
    "            return df_features\n",
    "\n",
    "        def _get_column_names(self, method):\n",
    "            return [f\"agg_{method}_{col}_grpby_{self.group_key}\" for col in self.group_values]\n",
    "\n",
    "        def fit_transform(self, df_train, y=None):\n",
    "            self.fit(df_train, y=y)\n",
    "            return self.transform(df_train)   \n",
    "\n",
    "    df[\"log_tempo\"] = np.log(df[\"tempo\"])\n",
    "    gfe = GroupFeatureExtractor(\n",
    "        \"region\", \n",
    "        ['popularity', 'duration_ms', 'acousticness', 'positiveness', 'danceability', 'loudness', 'energy', 'liveness', 'speechiness', 'instrumentalness', 'log_tempo'],\n",
    "        [\"zscore\"]\n",
    "    )\n",
    "    df = pd.concat([df, gfe.fit_transform(df)], axis=1)\n",
    "\n",
    "\n",
    "    class KNNFeatureExtractor:\n",
    "        def __init__(self, n_neighbors=5):\n",
    "            self.knn = KNeighborsClassifier(n_neighbors + 1)\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.knn.fit(X, y)\n",
    "            self.y = y if isinstance(y, np.ndarray) else np.array(y)\n",
    "            return self\n",
    "\n",
    "        def transform(self, X, is_train_data):\n",
    "            distances, indexes = self.knn.kneighbors(X)\n",
    "            distances = distances[:, 1:] if is_train_data else distances[:, :-1]\n",
    "            indexes = indexes[:, 1:] if is_train_data else indexes[:, :-1]\n",
    "            labels = self.y[indexes]\n",
    "            score_columns = [f\"knn_score_class{c:02d}\" for c in range(N_CLASSES)]\n",
    "            df_knn = pd.DataFrame(\n",
    "                [np.bincount(labels_, distances_, N_CLASSES) for labels_, distances_ in zip(labels, 1.0 / distances)],\n",
    "                columns=score_columns\n",
    "            )\n",
    "            df_knn[\"max_knn_scores\"] = df_knn.max(1)\n",
    "            for col in score_columns:\n",
    "                df_knn[f\"sub_max_knn_scores_{col}\"] = df_knn[\"max_knn_scores\"] - df_knn[col]\n",
    "            for i, col1 in enumerate(score_columns):\n",
    "                for j, col2 in enumerate(score_columns[i+1:], i+1):\n",
    "                    if {i, j} & {8, 10}:\n",
    "                        df_knn[f\"sub_{col1}_{col2}\"] = df_knn[col1] - df_knn[col2]\n",
    "            df_knn[\"sum_knn_scores\"] = df_knn.sum(1)\n",
    "\n",
    "            return df_knn\n",
    "\n",
    "\n",
    "    # feature scaling\n",
    "\n",
    "    df[\"log_tempo\"] = np.log(df[\"tempo\"])\n",
    "    for col in [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'log_tempo', 'num_nans',\n",
    "    ]:\n",
    "        df[\"standardscaled_\" + col] = StandardScaler().fit_transform(df[[col]])[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "    df_train, df_test = split_train_test(df)\n",
    "    target = df_train[\"genre\"]\n",
    "    \n",
    "    \n",
    "    # train\n",
    "    \n",
    "    N_SPLITS = 15\n",
    "    SEED_SKF = 37\n",
    "    np.random.seed(37)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\n",
    "    oof = np.zeros((len(df_train), N_CLASSES))\n",
    "    predictions = np.zeros((len(df_test), N_CLASSES))\n",
    "    df_feature_importance = pd.DataFrame()\n",
    "\n",
    "    features_numerical = [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'tempo',\n",
    "        'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "        'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "        'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "        'region_S', 'region_T', 'region_unknown', 'countenc_region',\n",
    "        'num_nans',\n",
    "        'agg_zscore_popularity_grpby_region',\n",
    "        'agg_zscore_duration_ms_grpby_region',\n",
    "        'agg_zscore_acousticness_grpby_region',\n",
    "        'agg_zscore_positiveness_grpby_region',\n",
    "        'agg_zscore_danceability_grpby_region',\n",
    "        'agg_zscore_loudness_grpby_region', 'agg_zscore_energy_grpby_region',\n",
    "        'agg_zscore_liveness_grpby_region',\n",
    "        'agg_zscore_speechiness_grpby_region',\n",
    "        'agg_zscore_instrumentalness_grpby_region',\n",
    "        'agg_zscore_log_tempo_grpby_region',\n",
    "        'knn_score_class00', 'knn_score_class01',\n",
    "        'knn_score_class02', 'knn_score_class03', 'knn_score_class04',\n",
    "        'knn_score_class05', 'knn_score_class06', 'knn_score_class07',\n",
    "        'knn_score_class08', 'knn_score_class09', 'knn_score_class10',\n",
    "        'max_knn_scores',\n",
    "        'sub_max_knn_scores_knn_score_class00',\n",
    "        'sub_max_knn_scores_knn_score_class01',\n",
    "        'sub_max_knn_scores_knn_score_class02',\n",
    "        'sub_max_knn_scores_knn_score_class03',\n",
    "        'sub_max_knn_scores_knn_score_class04',\n",
    "        'sub_max_knn_scores_knn_score_class05',\n",
    "        'sub_max_knn_scores_knn_score_class06',\n",
    "        'sub_max_knn_scores_knn_score_class07',\n",
    "        'sub_max_knn_scores_knn_score_class08',\n",
    "        'sub_max_knn_scores_knn_score_class09',\n",
    "        'sub_max_knn_scores_knn_score_class10',\n",
    "        'sub_knn_score_class00_knn_score_class08',\n",
    "        'sub_knn_score_class00_knn_score_class10',\n",
    "        'sub_knn_score_class01_knn_score_class08',\n",
    "        'sub_knn_score_class01_knn_score_class10',\n",
    "        'sub_knn_score_class02_knn_score_class08',\n",
    "        'sub_knn_score_class02_knn_score_class10',\n",
    "        'sub_knn_score_class03_knn_score_class08',\n",
    "        'sub_knn_score_class03_knn_score_class10',\n",
    "        'sub_knn_score_class04_knn_score_class08',\n",
    "        'sub_knn_score_class04_knn_score_class10',\n",
    "        'sub_knn_score_class05_knn_score_class08',\n",
    "        'sub_knn_score_class05_knn_score_class10',\n",
    "        'sub_knn_score_class06_knn_score_class08',\n",
    "        'sub_knn_score_class06_knn_score_class10',\n",
    "        'sub_knn_score_class07_knn_score_class08',\n",
    "        'sub_knn_score_class07_knn_score_class10',\n",
    "        'sub_knn_score_class08_knn_score_class09',\n",
    "        'sub_knn_score_class08_knn_score_class10',\n",
    "        'sub_knn_score_class09_knn_score_class10',\n",
    "        'sum_knn_scores'\n",
    "    ]\n",
    "    features_categorical = [\"labelenc_region\"]\n",
    "    features = features_numerical + features_categorical\n",
    "\n",
    "    for fold_, (indexes_trn, indexes_val) in enumerate(skf.split(df_train.values, target.values)):\n",
    "        print(f\"------------------------------ fold {fold_} ------------------------------\")\n",
    "\n",
    "        df_trn = df_train.loc[indexes_trn].reset_index(drop=True)\n",
    "        df_val = df_train.loc[indexes_val].reset_index(drop=True)\n",
    "        target_trn = target.loc[indexes_trn].reset_index(drop=True)\n",
    "        target_val = target.loc[indexes_val].reset_index(drop=True)\n",
    "\n",
    "        # make knn features\n",
    "        X = df_trn[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        knn_feature_extractor = KNNFeatureExtractor(knn_n_neighbors).fit(X, target_trn)\n",
    "        df_trn = pd.concat([df_trn, knn_feature_extractor.transform(X, is_train_data=True)], axis=1)\n",
    "        X = df_val[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        df_val = pd.concat([df_val, knn_feature_extractor.transform(X, is_train_data=False)], axis=1)\n",
    "        X = df_test[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        df_test_knn_features = knn_feature_extractor.transform(X, is_train_data=False)\n",
    "        for col in df_test_knn_features.columns:\n",
    "            df_test[col] = df_test_knn_features[col]\n",
    "\n",
    "        lgb_train = lgb.Dataset(\n",
    "            df_trn.loc[:, features],\n",
    "            label=target_trn,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "        )\n",
    "        lgb_valid = lgb.Dataset(\n",
    "            df_val.loc[:, features],\n",
    "            label=target_val,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "        )\n",
    "\n",
    "        lgb_params[\"learning_rate\"] = learning_rate + np.random.random() * 0.001  # おまじない\n",
    "        num_round = 999999999\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            lgb_train, \n",
    "            num_round, \n",
    "            valid_sets=[lgb_train, lgb_valid], \n",
    "            verbose_eval=300,\n",
    "            early_stopping_rounds=300 if num_round >= 1e8 else None,\n",
    "            fobj=None,\n",
    "            #feval=lgb_metric,\n",
    "        )\n",
    "\n",
    "        # cv\n",
    "        prediction_round = model.best_iteration+150 if num_round >= 1e8 else num_round  # おまじない\n",
    "        oof[indexes_val] = model.predict(df_val[features], num_iteration=prediction_round)\n",
    "\n",
    "        # feature importance\n",
    "        df_fold_importance = pd.DataFrame()\n",
    "        df_fold_importance[\"feature\"] = features\n",
    "        df_fold_importance[\"importance\"] = model.feature_importance()\n",
    "        df_fold_importance[\"fold\"] = fold_\n",
    "        df_feature_importance = pd.concat([df_feature_importance, df_fold_importance], axis=0)\n",
    "\n",
    "        # prediction for test data\n",
    "        predictions += model.predict(df_test[features], num_iteration=prediction_round) / N_SPLITS\n",
    "        print()\n",
    "\n",
    "    \n",
    "    score = f1_score(target, oof.argmax(1), average=\"macro\")\n",
    "    print(\"CV score (not reliable!)\")\n",
    "    print(f\"  f1: {score:8.5f}\")\n",
    "    print()\n",
    "    print(classification_report(target, oof.argmax(1)))\n",
    "    \n",
    "    \n",
    "    df_test[\"prediction\"] = predictions.argmax(1)\n",
    "    df_test[\"confidence\"] = predictions.max(1)\n",
    "    df_test[\"genre\"] = np.where(predictions.max(1) > pseudo_labeling_threshold, predictions.argmax(1), -100)\n",
    "    df = merge_train_test(df_train, df_test)\n",
    "    df_main[\"genre\"] = df_main[\"index\"].map(dict(df[[\"index\", \"genre\"]].values))\n",
    "    print((df_test[\"confidence\"] > pseudo_labeling_threshold).sum(), f\"rows were filled. (confidence>{pseudo_labeling_threshold})\")\n",
    "    print(\"filled test labels:\", np.bincount(df_test[df_test[\"genre\"]!=-100][\"genre\"]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       29\n",
       "1      152\n",
       "2      124\n",
       "3      376\n",
       "4       36\n",
       "5       97\n",
       "6       38\n",
       "7      313\n",
       "8     1437\n",
       "9       55\n",
       "10    1389\n",
       "Name: genre, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "first 10 test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4047</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4048</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4049</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4050</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4051</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4052</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4053</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4054</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4055</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  genre\n",
       "0   4046      7\n",
       "1   4047     10\n",
       "2   4048     10\n",
       "3   4049      8\n",
       "4   4050      8\n",
       "5   4051      7\n",
       "6   4052      8\n",
       "7   4053      8\n",
       "8   4054      3\n",
       "9   4055     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_submission = df_sample_sub.copy()\n",
    "df_submission[\"genre\"] = df_submission[\"index\"].map(dict(df_main[[\"index\", \"genre\"]].values))\n",
    "assert not df_submission[\"genre\"].isna().any()\n",
    "\n",
    "print(\"genre counts\")\n",
    "display(df_submission[\"genre\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nfirst 10 test data\")\n",
    "display(df_submission.head(10))\n",
    "\n",
    "# make submission file\n",
    "df_submission.to_csv(\"37_pseudo_submission.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
